{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.optimizers import SGD\n",
        "from keras import applications\n",
        "from keras.models import Model\n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.python.keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import TensorBoard\n",
        "from time import time\n",
        "from imutils import paths\n",
        "import cv2\n",
        "num_classes = 5\n",
        "img_size = (224,224)\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "batch_size = 32\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        'ML/ML/DR 2.0/test',\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Define the image directories for each class\n",
        "image_dir = 'ML/ML/DR 2.0/train'\n",
        "\n",
        "# Define the data augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Create separate data generators for each class, specifying augmentation only for folders 1-4\n",
        "datagen_0 = ImageDataGenerator(rescale=1./255)  # No augmentation for class '0'\n",
        "\n",
        "# Loop through each class and count images before augmentation\n",
        "for class_label in os.listdir(image_dir):\n",
        "    class_path = os.path.join(image_dir, class_label)\n",
        "\n",
        "    # Count the number of images before augmentation\n",
        "    before_augmentation_count = len(os.listdir(class_path))\n",
        "\n",
        "    # Create data generators for each class\n",
        "    if class_label == '0':\n",
        "        data_generator = datagen_0\n",
        "    else:\n",
        "        data_generator = datagen\n",
        "    \n",
        "    train_generator = data_generator.flow_from_directory(\n",
        "        class_path,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        classes=[class_label],#[class_label]\n",
        "        shuffle=False  # Disable shuffling for accurate counting\n",
        "    )\n",
        "\n",
        "    \n",
        "# train_generator_0 = datagen_0.flow_from_directory(\n",
        "#     image_dir,\n",
        "#     target_size=img_size,\n",
        "#     batch_size=batch_size,\n",
        "#     class_mode='categorical',  \n",
        "#     classes=['0']\n",
        "# )\n",
        "\n",
        "# train_generator_1_4 = datagen.flow_from_directory(\n",
        "#     image_dir,\n",
        "#     target_size=img_size,\n",
        "#     batch_size=batch_size,\n",
        "#     class_mode='categorical',  \n",
        "#     classes=['1', '2', '3', '4']\n",
        "# )\n",
        "import random\n",
        "import cv2\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "imagePaths = sorted(list(paths.list_images( \"C:\\\\Users\\\\Nishi Mahajan\\\\Desktop\\\\python\\\\ML\\\\ML\\\\DR\\\\\" )))\n",
        "                                           \n",
        "random.seed(42)\n",
        "random.shuffle(imagePaths)\n",
        "\n",
        "# loop over the input images\n",
        "for imagePath in imagePaths:\n",
        "    # load the image, pre-process it, and store it in the data list\n",
        "    image = cv2.imread(imagePath)\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
        "    clahe_image = clahe.apply(image)\n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(clahe_image, 30, 150)  # Adjust thresholds as needed\n",
        "\n",
        "    # Apply thresholding to segment retinal features\n",
        "    _, binary_image = cv2.threshold(edges, 50, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Apply morphological opening for noise reduction\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Apply vessel segmentation using morphological operations\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    vessel_segmentation = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
        "    vessel_segmentation = cv2.morphologyEx(\n",
        "    vessel_segmentation, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # # Save the preprocessed image and vessel segmentation result\n",
        "    # cv2.imwrite('preprocessed_retinal_image.jpg', vessel_segmentation)\n",
        "    new_image = img_to_array(vessel_segmentation)\n",
        "    data.append(new_image)\n",
        "\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    labels.append(label)\n",
        "\n",
        "# loop over the input images\n",
        "# for imagePath in imagePaths:\n",
        "#     # load the image, pre-process it, and store it in the data list\n",
        "#     image = cv2.imread(imagePath)\n",
        "#     if image is None:\n",
        "#         continue\n",
        "#     image = cv2.resize(image, img_size)\n",
        "#     image = img_to_array(image)\n",
        "#     data.append(image)\n",
        " \n",
        "#  # extract the class label from the image path and update the labels list\n",
        "#     label = imagePath.split(os.path.sep)[-2]\n",
        "# # label = 0 if label == \"X\" else 1\n",
        "#     labels.append(label)\n",
        "print(labels)\n",
        "imagePaths\n",
        "data[10]\n",
        "plt.imshow(data[30]/255)\n",
        "data[0].shape\n",
        "model = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (224, 224, 3))\n",
        "model.summary()\n",
        "for layers in model.layers:\n",
        "    layers.trainable = False\n",
        "model.summary()\n",
        "l = model.output\n",
        "\n",
        "l = Flatten()(l)\n",
        "# l = GlobalAveragePooling2D()(l)\n",
        "l = Dense(128, activation=\"relu\")(l) # Adding a single dense layer over the pre-built model\n",
        "\n",
        "predictions = Dense(num_classes, activation=\"softmax\")(l)\n",
        "final_model = Model(inputs=model.input, outputs=predictions)\n",
        "final_model.summary()\n",
        "final_model.compile(optimizer='adam', metrics=[\"accuracy\"], loss=\"categorical_crossentropy\")\n",
        "NAME = \"VGG16\"\n",
        "tensorboard = TensorBoard(log_dir='logs_vgg/{}'.format(NAME))\n",
        "filepath = \"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [tensorboard,es, checkpoint]\n",
        "import math\n",
        "total_samples = len(train_generator.filenames)\n",
        "steps_per_epoch = math.ceil(total_samples / batch_size)\n",
        "\n",
        "validation_data_length = len(validation_generator.filenames)\n",
        "validation_steps = validation_data_length // batch_size\n",
        "print(steps_per_epoch) \n",
        "print(validation_steps)\n",
        "final_model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch, \n",
        "        epochs=10,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_steps,\n",
        "        callbacks=callbacks_list)\n",
        "\n",
        "final_model.save('complete_model.h5')\n",
        "from keras.models import load_model \n",
        "\n",
        "\n",
        "loadedmodel=load_model(\"complete_model.h5\")\n",
        "#load_model.load_weights(\"first_try.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "loadedmodel.summary()\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# img_pred = image.load_img('ML/ML/DR/single_prediction/Proliferative_DR_EDA01.jpeg', target_size = img_size)\n",
        "# img_pred = img_pred.reshape(224, 224, 3)\n",
        "# img_pred = np.mean(img_pred, axis=0)\n",
        "image = cv2.imread('ML/ML/DR/single_prediction/Moderate_DR_222.png')\n",
        "img_pred = np.array(image)\n",
        "plt.imshow(img_pred)\n",
        "# img_pred = image.img_to_array(img_pred)\n",
        "# img_pred = np.squeeze(img_pred, axis=0)\n",
        "img_pred = cv2.resize(img_pred, (224, 224))\n",
        "img_pred = np.expand_dims(img_pred, axis = 0)\n",
        "img_pred = img_pred / 255.0 \n",
        "rslt = loadedmodel.predict(img_pred)\n",
        "\n",
        "# ind = train_generator.class_indices\n",
        "class_indices = train_generator.class_indices\n",
        "# predicted_class = labels[np.argmax(predictions)]\n",
        "predicted_class_label = list(class_indices.keys())[np.argmax(rslt)]\n",
        "\n",
        "print(\"Predicted class:\", predicted_class_label)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
